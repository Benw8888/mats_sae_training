{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f66b5349790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import plotly.express as px\n",
    "from transformer_lens import utils\n",
    "from datasets import load_dataset\n",
    "from typing import  Dict\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from collections.abc import Generator\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import Any, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from fastcluster import linkage\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "import wandb\n",
    "from sae_training.activations_store import ActivationsStore\n",
    "from sae_training.evals import run_evals\n",
    "from sae_training.optim import get_scheduler\n",
    "from sae_training.sparse_autoencoder import SparseAutoencoder\n",
    "from sae_training.sae_group import SAEGroup\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\" \n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by downloading them from huggingface\n",
    "from huggingface_hub import hf_hub_download\n",
    "REPO_ID = \"Benw8888/lp_saes\"\n",
    "layer = 3 # 6 for gpt2, 3 for pythia\n",
    "uuid_str = \"vg840plj\" # c0es5ci0 for L0.6, 1w6fnqmj for L1, vg840plj for L0.6 pythia, uloaub10 for L1 pythia\n",
    "p_name = \"0.6\"\n",
    "local_folder = f\"/root/mats_sae_training/checkpoints/{uuid_str}\"\n",
    "model_name = \"pythia14m\" #gpt2\n",
    "\n",
    "# file_strings = [\n",
    "#     \"final_sae_group_gpt2-small_blocks.6.hook_resid_pre_12288_log_feature_sparsity.pt\",\n",
    "#     \"final_sae_group_gpt2-small_blocks.6.hook_resid_pre_12288.pt\",\n",
    "# ]\n",
    "file_strings = [\n",
    "    \"final_sae_group_EleutherAI_pythia-14m_blocks.3.hook_resid_pre_8192_log_feature_sparsity.pt\",\n",
    "    \"final_sae_group_EleutherAI_pythia-14m_blocks.3.hook_resid_pre_8192.pt\",\n",
    "]\n",
    "fs = file_strings[-1]\n",
    "\n",
    "# FILENAME = f\"{uuid_str}/final_sae_group_gpt2-small_blocks.{layer}.hook_resid_pre_49152.pt\"\n",
    "\n",
    "# path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
    "path = f\"/root/mats_sae_training/checkpoints/{uuid_str}/{fs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-14m into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mats_sae_training/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is not tokenized! Updating config.\n",
      "Generating 42 saes\n",
      "Run name: 64-L1-3e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-09, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/365ai50g/4c5i9tgn')\n",
      "Run name: 64-L1-3e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-09, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/meqktatk/f8qdeo67')\n",
      "Run name: 64-L1-5.6e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-09, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/ksat6y12/2iy3k7ku')\n",
      "Run name: 64-L1-5.6e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-09-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-09, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/6sgnbv15/wh4tsqj8')\n",
      "Run name: 64-L1-1e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-08, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/0ula70u9/ih82accw')\n",
      "Run name: 64-L1-1e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-08, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/ucrtg98r/ch6bf96t')\n",
      "Run name: 64-L1-1.8e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-08, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/mdbwe5c6/27sm2m9g')\n",
      "Run name: 64-L1-1.8e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-08, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/hjtj9ati/hgtzzf1l')\n",
      "Run name: 64-L1-3e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-08, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/vpc0wc65/oruwvprn')\n",
      "Run name: 64-L1-3e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-08, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/pbvr9uch/jf8tjv29')\n",
      "Run name: 64-L1-5.6e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-08, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/uqxfpkhl/p7uvwx6s')\n",
      "Run name: 64-L1-5.6e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-08-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-08, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/02w8mjgo/0gt5q2sz')\n",
      "Run name: 64-L1-1e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-07, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/7wvi1ex8/12e8ums9')\n",
      "Run name: 64-L1-1e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-07, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/mj9u2kgz/98f0xuty')\n",
      "Run name: 64-L1-1.8e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-07, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/ek7v00b8/dew45rfq')\n",
      "Run name: 64-L1-1.8e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-07, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/65zjc9dx/hzf104pn')\n",
      "Run name: 64-L1-3e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-07, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/gqu9j06s/4qeli25k')\n",
      "Run name: 64-L1-3e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-07, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/aggo9zwu/30ooo17o')\n",
      "Run name: 64-L1-5.6e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-07, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/6oln4anc/md9vq1mm')\n",
      "Run name: 64-L1-5.6e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-07-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-07, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/ucp4nxqp/uwj2zdku')\n",
      "Run name: 64-L1-1e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-06, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/yd42enno/ql4ibqfp')\n",
      "Run name: 64-L1-1e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-06, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/bmnp8458/yosm6cxs')\n",
      "Run name: 64-L1-1.8e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-06, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/t2hbd7l4/vz8eaoin')\n",
      "Run name: 64-L1-1.8e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-06, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/zhoqv69q/gwe6jw0g')\n",
      "Run name: 64-L1-3e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-06, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/tu03xj4k/tfi1cq2n')\n",
      "Run name: 64-L1-3e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-06, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/r4rwifod/bfrmwwq8')\n",
      "Run name: 64-L1-5.6e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-06, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/88fubhkn/96y1i7j2')\n",
      "Run name: 64-L1-5.6e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-06-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-06, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/1hu9t4zp/grq5ekux')\n",
      "Run name: 64-L1-1e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-05, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/q4idywut/bou7bwn7')\n",
      "Run name: 64-L1-1e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1e-05, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/73f1f509/zpvuko10')\n",
      "Run name: 64-L1-1.8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-05, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/rcaf5rkh/bvx3858t')\n",
      "Run name: 64-L1-1.8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-1.8e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=1.8e-05, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/5x0gvmc4/7mz095rn')\n",
      "Run name: 64-L1-3e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-05, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/56obj99z/3ehjqc0m')\n",
      "Run name: 64-L1-3e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-3e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=3e-05, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/s1n4pede/b9hsjhom')\n",
      "Run name: 64-L1-5.6e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-05, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/6coj2qzq/izjjbt2b')\n",
      "Run name: 64-L1-5.6e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-5.6e-05-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=5.6e-05, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/1wnmsx10/my68tjh5')\n",
      "Run name: 64-L1-0.0001-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.0001-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.0001, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/3xbo8ah9/ey5ay2te')\n",
      "Run name: 64-L1-0.0001-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.0001-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.0001, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/t12mxxoo/v43j0qil')\n",
      "Run name: 64-L1-0.00018-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.00018-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.00018, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/jna0bv7z/tizpohgy')\n",
      "Run name: 64-L1-0.00018-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.00018-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.00018, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/oxzg2sln/v1szk9kk')\n",
      "Run name: 64-L1-0.0003-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.0003-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.0003, lp_norm=0.6, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/lxvb5ddu/ljro9wyd')\n",
      "Run name: 64-L1-0.0003-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 64-L1-0.0003-LR-0.0004-Tokens-3.000e+08\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 2621.44\n",
      "We will reset the sparsity calculation 73 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "LanguageModelSAERunnerConfig(model_name='EleutherAI/pythia-14m', hook_point='blocks.{layer}.hook_resid_pre', hook_point_layer=3, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/EleutherAI_pythia-14m/blocks.{layer}.hook_resid_pre', d_in=128, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device=device(type='cuda'), seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, d_sae=8192, l1_coefficient=0.0003, lp_norm=0.8, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=False, feature_sampling_window=1000, dead_feature_window=5000, dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=3, checkpoint_path='checkpoints/vg840plj/50oap2v1/8iw1eunt')\n"
     ]
    }
   ],
   "source": [
    "# We can then load the SAE, dataset and model using the session loader\n",
    "model, sae_group, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path = path\n",
    ")\n",
    "log_frequencies = torch.load(f\"/root/mats_sae_training/checkpoints/{uuid_str}/{file_strings[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Layer 3, p_norm 0.6, alpha 3e-09\n",
      "1: Layer 3, p_norm 0.8, alpha 3e-09\n",
      "2: Layer 3, p_norm 0.6, alpha 5.6e-09\n",
      "3: Layer 3, p_norm 0.8, alpha 5.6e-09\n",
      "4: Layer 3, p_norm 0.6, alpha 1e-08\n",
      "5: Layer 3, p_norm 0.8, alpha 1e-08\n",
      "6: Layer 3, p_norm 0.6, alpha 1.8e-08\n",
      "7: Layer 3, p_norm 0.8, alpha 1.8e-08\n",
      "8: Layer 3, p_norm 0.6, alpha 3e-08\n",
      "9: Layer 3, p_norm 0.8, alpha 3e-08\n",
      "10: Layer 3, p_norm 0.6, alpha 5.6e-08\n",
      "11: Layer 3, p_norm 0.8, alpha 5.6e-08\n",
      "12: Layer 3, p_norm 0.6, alpha 1e-07\n",
      "13: Layer 3, p_norm 0.8, alpha 1e-07\n",
      "14: Layer 3, p_norm 0.6, alpha 1.8e-07\n",
      "15: Layer 3, p_norm 0.8, alpha 1.8e-07\n",
      "16: Layer 3, p_norm 0.6, alpha 3e-07\n",
      "17: Layer 3, p_norm 0.8, alpha 3e-07\n",
      "18: Layer 3, p_norm 0.6, alpha 5.6e-07\n",
      "19: Layer 3, p_norm 0.8, alpha 5.6e-07\n",
      "20: Layer 3, p_norm 0.6, alpha 1e-06\n",
      "21: Layer 3, p_norm 0.8, alpha 1e-06\n",
      "22: Layer 3, p_norm 0.6, alpha 1.8e-06\n",
      "23: Layer 3, p_norm 0.8, alpha 1.8e-06\n",
      "24: Layer 3, p_norm 0.6, alpha 3e-06\n",
      "25: Layer 3, p_norm 0.8, alpha 3e-06\n",
      "26: Layer 3, p_norm 0.6, alpha 5.6e-06\n",
      "27: Layer 3, p_norm 0.8, alpha 5.6e-06\n",
      "28: Layer 3, p_norm 0.6, alpha 1e-05\n",
      "29: Layer 3, p_norm 0.8, alpha 1e-05\n",
      "30: Layer 3, p_norm 0.6, alpha 1.8e-05\n",
      "31: Layer 3, p_norm 0.8, alpha 1.8e-05\n",
      "32: Layer 3, p_norm 0.6, alpha 3e-05\n",
      "33: Layer 3, p_norm 0.8, alpha 3e-05\n",
      "34: Layer 3, p_norm 0.6, alpha 5.6e-05\n",
      "35: Layer 3, p_norm 0.8, alpha 5.6e-05\n",
      "36: Layer 3, p_norm 0.6, alpha 0.0001\n",
      "37: Layer 3, p_norm 0.8, alpha 0.0001\n",
      "38: Layer 3, p_norm 0.6, alpha 0.00018\n",
      "39: Layer 3, p_norm 0.8, alpha 0.00018\n",
      "40: Layer 3, p_norm 0.6, alpha 0.0003\n",
      "41: Layer 3, p_norm 0.8, alpha 0.0003\n",
      "Only using sae with p_norm 0.6, alpha 1.8e-05\n"
     ]
    }
   ],
   "source": [
    "for i, sae in enumerate(sae_group):\n",
    "    hyp = sae.cfg\n",
    "    print(f\"{i}: Layer {hyp.hook_point_layer}, p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")\n",
    "\n",
    "# select alpha 1.6e-6 for L0.6, 8e-5 for L1\n",
    "if model_name==\"gpt2\":\n",
    "    if hyp.lp_norm == 0.6:\n",
    "        id = 6\n",
    "        sae = list(sae_group)[id]\n",
    "        sae_lfreq = log_frequencies[id]\n",
    "        hyp = sae.cfg\n",
    "        print(f\"Only using sae with p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")\n",
    "        \n",
    "    if hyp.lp_norm == 1:\n",
    "        id = 3\n",
    "        sae = list(sae_group)[id]\n",
    "        sae_lfreq = log_frequencies[id]\n",
    "        hyp = sae.cfg\n",
    "        print(f\"Only using sae with p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")\n",
    "        \n",
    "if model_name==\"pythia14m\":\n",
    "    if p_name == \"0.6\":\n",
    "        id = 30\n",
    "        sae = list(sae_group)[id]\n",
    "        sae_lfreq = log_frequencies[id]\n",
    "        hyp = sae.cfg\n",
    "        print(f\"Only using sae with p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")\n",
    "        \n",
    "    if p_name == \"0.8\":\n",
    "        id = 31\n",
    "        sae = list(sae_group)[id]\n",
    "        sae_lfreq = log_frequencies[id]\n",
    "        hyp = sae.cfg\n",
    "        print(f\"Only using sae with p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")\n",
    "        \n",
    "    if p_name == \"1\":\n",
    "        id = 9\n",
    "        sae = list(sae_group)[id]\n",
    "        sae_lfreq = log_frequencies[id]\n",
    "        hyp = sae.cfg\n",
    "        print(f\"Only using sae with p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(\n",
    "    vecs1: Union[torch.Tensor, torch.nn.parameter.Parameter, npt.NDArray],\n",
    "    vecs2: Union[torch.Tensor, torch.nn.parameter.Parameter, npt.NDArray],\n",
    ") -> np.ndarray:\n",
    "    vecs = [vecs1, vecs2]\n",
    "    for i in range(len(vecs)):\n",
    "        if not isinstance(vecs[i], np.ndarray):\n",
    "            vecs[i] = vecs[i].detach().cpu().numpy()  # type: ignore\n",
    "    vecs1, vecs2 = vecs\n",
    "    normalize = lambda v: (v.T / np.linalg.norm(v, axis=1)).T\n",
    "    vecs1_norm = normalize(vecs1)\n",
    "    vecs2_norm = normalize(vecs2)\n",
    "\n",
    "    return vecs1_norm @ vecs2_norm.T\n",
    "\n",
    "class BatchCorrelationCalculator:\n",
    "    def __init__(self, feature_dim_x, feature_dim_y, device=\"cpu\"):\n",
    "        # Initialize sums needed for correlation calculation for each feature dimension\n",
    "        self.sum_x = torch.zeros(feature_dim_x, device=device)\n",
    "        self.sum_y = torch.zeros(feature_dim_y, device=device)\n",
    "        self.sum_x2 = torch.zeros(feature_dim_x, device=device)\n",
    "        self.sum_y2 = torch.zeros(feature_dim_y, device=device)\n",
    "        self.sum_xy = torch.zeros(\n",
    "            (feature_dim_x, feature_dim_y), device=device\n",
    "        )  # This now becomes a matrix\n",
    "        self.n = 0\n",
    "        self.device = device\n",
    "\n",
    "    def update(self, x_batch, y_batch):\n",
    "        # Ensure input batches are torch tensors\n",
    "        x_batch = x_batch.to(self.device)\n",
    "        y_batch = y_batch.to(self.device)\n",
    "\n",
    "        # Update running sums with a new batch\n",
    "        self.sum_x += torch.sum(x_batch, dim=0)\n",
    "        self.sum_y += torch.sum(y_batch, dim=0)\n",
    "        self.sum_x2 += torch.sum(x_batch**2, dim=0)\n",
    "        self.sum_y2 += torch.sum(y_batch**2, dim=0)\n",
    "        for i in range(x_batch.shape[1]):  # Iterate over features in x\n",
    "            for j in range(y_batch.shape[1]):  # Iterate over features in y\n",
    "                self.sum_xy[i, j] += torch.sum(x_batch[:, i] * y_batch[:, j])\n",
    "        self.n += x_batch.shape[0]\n",
    "\n",
    "    def compute_correlation(self):\n",
    "        # Compute Pearson correlation coefficient matrix between features of the two vectors\n",
    "        numerator = self.n * self.sum_xy - torch.ger(self.sum_x, self.sum_y)\n",
    "        denominator = torch.sqrt(\n",
    "            torch.ger(self.n * self.sum_x2 - self.sum_x**2, self.n * self.sum_y2 - self.sum_y**2)\n",
    "        )\n",
    "\n",
    "        # Handle division by zero for cases with no variance\n",
    "        valid = denominator != 0\n",
    "        correlation_matrix = torch.zeros_like(denominator)\n",
    "        correlation_matrix[valid] = numerator[valid] / denominator[valid]\n",
    "\n",
    "        # Set correlations to 0 where denominator is 0 (indicating no variance)\n",
    "        correlation_matrix[~valid] = 0\n",
    "\n",
    "        return correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Metric Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating SAE:   0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating SAE: 100%|| 995328/1000000 [00:20<00:00, 85220.46it/s]"
     ]
    }
   ],
   "source": [
    "def wandb_log_suffix(cfg, hyperparams):\n",
    "    # Create a mapping from cfg list keys to their corresponding hyperparams attributes\n",
    "    key_mapping = {\n",
    "        \"hook_point_layer\": \"layer\",\n",
    "        \"l1_coefficient\": \"coeff\",\n",
    "        \"lp_norm\": \"l\",\n",
    "        \"lr\": \"lr\"\n",
    "    }\n",
    "\n",
    "    # Generate the suffix by iterating over the keys that have list values in cfg\n",
    "    suffix = \"\".join(f\"_{key_mapping.get(key, key)}{getattr(hyperparams, key, '')}\" \n",
    "                    for key, value in vars(cfg).items() if isinstance(value, list))\n",
    "    return suffix\n",
    "\n",
    "batch_size=sae_group.cfg.train_batch_size\n",
    "feature_sampling_window=sae_group.cfg.feature_sampling_window\n",
    "dead_feature_threshold=sae_group.cfg.dead_feature_threshold\n",
    "use_wandb=False  # sae_group.cfg.log_to_wandb\n",
    "wandb_log_frequency=1  # sae_group.cfg.wandb_log_frequency # should we log faster when evaluating?\n",
    "\n",
    "# Only run evals for less time than training:\n",
    "total_training_tokens = 1_000_000\n",
    "total_training_steps = total_training_tokens // batch_size\n",
    "n_training_steps = 0\n",
    "n_training_tokens = 0\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.init(project=sae_group.cfg.wandb_project, config=sae_group.cfg, name=f\"eval_{sae_group.cfg.run_name}\")\n",
    "\n",
    "\n",
    "# things to store for each sae:\n",
    "# act_freq_scores, n_forward_passes_since_fired, n_frac_active_tokens, optimizer, scheduler, \n",
    "\n",
    "# Filter for only the SAEs we want (allow for all of sae_group and also single SAEs)\n",
    "sae_list = [sae]\n",
    "num_saes = len(sae_list)\n",
    "# track active features\n",
    "\n",
    "act_freq_scores = [\n",
    "    torch.zeros(\n",
    "        sparse_autoencoder.cfg.d_sae, device=sparse_autoencoder.cfg.device\n",
    "    ) for sparse_autoencoder in sae_list\n",
    "]\n",
    "n_forward_passes_since_fired = [\n",
    "    torch.zeros(\n",
    "        sparse_autoencoder.cfg.d_sae, device=sparse_autoencoder.cfg.device\n",
    "    ) for sparse_autoencoder in sae_list\n",
    "]\n",
    "n_frac_active_tokens = [0  for _ in range(num_saes)]\n",
    "# corr_calculator = [\n",
    "#     BatchCorrelationCalculator(sparse_autoencoder.cfg.d_sae, sparse_autoencoder.cfg.d_sae)\n",
    "#     for sparse_autoencoder in sae_group\n",
    "# ]\n",
    "co_occurrences = [\n",
    "    torch.zeros((sparse_autoencoder.cfg.d_sae, sparse_autoencoder.cfg.d_sae), \n",
    "                device=sparse_autoencoder.cfg.device)\n",
    "    for sparse_autoencoder in sae_list\n",
    "]\n",
    "occurrences = [\n",
    "    torch.zeros((sparse_autoencoder.cfg.d_sae), \n",
    "                device=sparse_autoencoder.cfg.device)\n",
    "    for sparse_autoencoder in sae_list\n",
    "]\n",
    "\n",
    "\n",
    "all_layers = sae_group.cfg.hook_point_layer\n",
    "if not isinstance(all_layers, list):\n",
    "    all_layers = [all_layers]\n",
    "    \n",
    "# compute the geometric median of the activations of each layer\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(total=total_training_tokens, desc=\"Evaluating SAE\")\n",
    "    while n_training_tokens < total_training_tokens:\n",
    "        # Do a training step.\n",
    "        layer_acts = activation_store.next_batch()\n",
    "        n_training_tokens += batch_size\n",
    "        \n",
    "        for i, (sparse_autoencoder), in enumerate(sae_list):\n",
    "            hyperparams = sparse_autoencoder.cfg\n",
    "            layer_id = all_layers.index(hyperparams.hook_point_layer)\n",
    "            sae_in = layer_acts[:,layer_id,:]\n",
    "            \n",
    "            sparse_autoencoder.eval()\n",
    "            # Make sure the W_dec is still zero-norm\n",
    "            sparse_autoencoder.set_decoder_norm_to_unit_norm()\n",
    "\n",
    "            # log and then reset the feature sparsity every feature_sampling_window steps\n",
    "            if (n_training_steps + 1) % feature_sampling_window == 0:\n",
    "                feature_sparsity = act_freq_scores[i] / n_frac_active_tokens[i]\n",
    "                log_feature_sparsity = torch.log10(feature_sparsity + 1e-10).detach().cpu()\n",
    "\n",
    "                if use_wandb:\n",
    "                    suffix = wandb_log_suffix(sae_group.cfg, hyperparams)\n",
    "                    wandb_histogram = wandb.Histogram(log_feature_sparsity.numpy())\n",
    "                    wandb.log(\n",
    "                        {\n",
    "                            f\"metrics/mean_log10_feature_sparsity{suffix}\": log_feature_sparsity.mean().item(),\n",
    "                            f\"plots/feature_density_line_chart{suffix}\": wandb_histogram,\n",
    "                            f\"sparsity/below_1e-5{suffix}\": (feature_sparsity < 1e-5).sum().item(),\n",
    "                            f\"sparsity/below_1e-6{suffix}\": (feature_sparsity < 1e-6).sum().item(),\n",
    "                        },\n",
    "                        step=n_training_steps,\n",
    "                    )\n",
    "\n",
    "                act_freq_scores[i] = torch.zeros(\n",
    "                    sparse_autoencoder.cfg.d_sae, device=sparse_autoencoder.cfg.device\n",
    "                )\n",
    "                n_frac_active_tokens[i] = 0\n",
    "\n",
    "            ghost_grad_neuron_mask = (\n",
    "                n_forward_passes_since_fired[i] > sparse_autoencoder.cfg.dead_feature_window\n",
    "            ).bool()\n",
    "            \n",
    "\n",
    "            # Forward and Backward Passes\n",
    "            (\n",
    "                sae_out,\n",
    "                feature_acts,\n",
    "                loss,\n",
    "                mse_loss,\n",
    "                l1_loss,\n",
    "                ghost_grad_loss,\n",
    "            ) = sparse_autoencoder(\n",
    "                sae_in,\n",
    "                ghost_grad_neuron_mask,\n",
    "            )\n",
    "            did_fire = (feature_acts > 0).float().sum(-2) > 0\n",
    "            n_forward_passes_since_fired[i] += 1\n",
    "            n_forward_passes_since_fired[i][did_fire] = 0\n",
    "            \n",
    "            # Update auto-correlation tracker\n",
    "            # corr_calculator[i].update(feature_acts, feature_acts)\n",
    "            \n",
    "            # update co-occur\n",
    "            binary_acts = (feature_acts > 0) + 0.0\n",
    "            co_occurrences[i] += ((binary_acts.T) @ (binary_acts))\n",
    "            occurrences[i] += binary_acts.sum(dim=0)\n",
    "            \n",
    "            # Calculate the sparsities, and add it to a list, calculate sparsity metrics\n",
    "            act_freq_scores[i] += (feature_acts.abs() > 0).float().sum(0)\n",
    "            n_frac_active_tokens[i] += batch_size\n",
    "            feature_sparsity = act_freq_scores[i] / n_frac_active_tokens[i]\n",
    "\n",
    "            if use_wandb and ((n_training_steps + 1) % wandb_log_frequency == 0):\n",
    "                # metrics for currents acts\n",
    "                l0 = (feature_acts > 0).float().sum(-1).mean()\n",
    "\n",
    "                per_token_l2_loss = (sae_out - sae_in).pow(2).sum(dim=-1).squeeze()\n",
    "                total_variance = (sae_in - sae_in.mean(0)).pow(2).sum(-1)\n",
    "                explained_variance = 1 - per_token_l2_loss / total_variance\n",
    "\n",
    "                suffix = wandb_log_suffix(sae_group.cfg, hyperparams)\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        # losses\n",
    "                        f\"losses/mse_loss{suffix}\": mse_loss.item(),\n",
    "                        f\"losses/l1_loss{suffix}\": l1_loss.item()\n",
    "                        / sparse_autoencoder.l1_coefficient,  # normalize by l1 coefficient\n",
    "                        f\"losses/ghost_grad_loss{suffix}\": ghost_grad_loss.item(),\n",
    "                        f\"losses/overall_loss{suffix}\": loss.item(),\n",
    "                        # variance explained\n",
    "                        f\"metrics/explained_variance{suffix}\": explained_variance.mean().item(),\n",
    "                        f\"metrics/explained_variance_std{suffix}\": explained_variance.std().item(),\n",
    "                        f\"metrics/l0{suffix}\": l0.item(),\n",
    "                        # sparsity\n",
    "                        f\"sparsity/mean_passes_since_fired{suffix}\": n_forward_passes_since_fired[i].mean().item(),\n",
    "                        f\"sparsity/dead_features{suffix}\": ghost_grad_neuron_mask.sum().item(),\n",
    "                        f\"details/n_training_tokens{suffix}\": n_training_tokens,\n",
    "                    },\n",
    "                    step=n_training_steps,\n",
    "                )\n",
    "\n",
    "            # record evals more frequently than while training\n",
    "            if use_wandb and ((n_training_steps) % (wandb_log_frequency) == 0):\n",
    "                sparse_autoencoder.eval()\n",
    "                suffix = wandb_log_suffix(sae_group.cfg, hyperparams)\n",
    "                run_evals(sparse_autoencoder, activation_store, model, n_training_steps, suffix=suffix)\n",
    "                sparse_autoencoder.train()\n",
    "                \n",
    "        n_training_steps += 1\n",
    "        # pbar.set_description(\n",
    "        #     f\"{n_training_steps}| MSE Loss {mse_loss.item():.3f} | L1 {l1_loss.item():.3f}\"\n",
    "        # )\n",
    "        pbar.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate jaccard coefficient (co_occur / (either one firing))\n",
    "\n",
    "jaccard = []\n",
    "\n",
    "for i, (sparse_autoencoder), in enumerate(sae_list):\n",
    "    co_occ = co_occurrences[i]\n",
    "    occ = occurrences[i]\n",
    "    jac = co_occ / (occ.unsqueeze(0) + occ.unsqueeze(1) - co_occ)\n",
    "    jac = jac.nan_to_num(0)\n",
    "    jaccard.append(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Cosine Sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3, p_norm 0.6, alpha 1.8e-05\n"
     ]
    }
   ],
   "source": [
    "# id = 4 # 30\n",
    "# sae = list(sae_group)[id]\n",
    "hyp = sae.cfg\n",
    "jaccard_matrix = jaccard[0]\n",
    "print(f\"Layer {hyp.hook_point_layer}, p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alive(log_freq, threshold=1e-6):\n",
    "    alive = log_freq > np.log10(threshold)\n",
    "    return alive\n",
    "\n",
    "def get_cosims(sae, log_freq=None, threshold=1e-6, alive=None):\n",
    "    feats = sae.W_dec.data\n",
    "    if alive is not None:\n",
    "        feats = feats[alive]\n",
    "    elif log_freq is not None:\n",
    "        alive = log_freq > np.log10(threshold)\n",
    "        feats = feats[alive]\n",
    "    \n",
    "    normed_feats = nn.functional.normalize(feats, dim=1)\n",
    "    cosim_matrix = (\n",
    "        (\n",
    "            normed_feats\n",
    "            @ normed_feats.mT\n",
    "        )\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    return cosim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "def seriation(Z,N,cur_index):\n",
    "    '''\n",
    "        input:\n",
    "            - Z is a hierarchical tree (dendrogram)\n",
    "            - N is the number of points given to the clustering process\n",
    "            - cur_index is the position in the tree for the recursive traversal\n",
    "        output:\n",
    "            - order implied by the hierarchical tree Z\n",
    "            \n",
    "        seriation computes the order implied by a hierarchical tree (dendrogram)\n",
    "    '''\n",
    "    if cur_index < N:\n",
    "        return [cur_index]\n",
    "    else:\n",
    "        left = int(Z[cur_index-N,0])\n",
    "        right = int(Z[cur_index-N,1])\n",
    "        return (seriation(Z,N,left) + seriation(Z,N,right))\n",
    "    \n",
    "def compute_serial_matrix(dist_mat,method=\"ward\"):\n",
    "    '''\n",
    "        input:\n",
    "            - dist_mat is a distance matrix\n",
    "            - method = [\"ward\",\"single\",\"average\",\"complete\"]\n",
    "        output:\n",
    "            - seriated_dist is the input dist_mat,\n",
    "              but with re-ordered rows and columns\n",
    "              according to the seriation, i.e. the\n",
    "              order implied by the hierarchical tree\n",
    "            - res_order is the order implied by\n",
    "              the hierarhical tree\n",
    "            - res_linkage is the hierarhical tree (dendrogram)\n",
    "        \n",
    "        compute_serial_matrix transforms a distance matrix into \n",
    "        a sorted distance matrix according to the order implied \n",
    "        by the hierarchical tree (dendrogram)\n",
    "    '''\n",
    "    N = len(dist_mat)\n",
    "    flat_dist_mat = dist_mat #squareform(dist_mat)\n",
    "    res_linkage = linkage(flat_dist_mat, method=method,preserve_input=True)\n",
    "    res_order = seriation(res_linkage, N, N + N-2)\n",
    "    return res_order, res_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.5607, 1.8949,  ..., 1.5590, 1.6600, 1.6399],\n",
       "        [1.5607, 0.0000, 1.5249,  ..., 1.5047, 1.8008, 1.4811],\n",
       "        [1.8949, 1.5249, 0.0000,  ..., 1.5601, 1.4979, 1.5007],\n",
       "        ...,\n",
       "        [1.5590, 1.5047, 1.5601,  ..., 0.0000, 1.6174, 1.5430],\n",
       "        [1.6600, 1.8008, 1.4979,  ..., 1.6174, 0.0000, 1.7906],\n",
       "        [1.6399, 1.4811, 1.5007,  ..., 1.5430, 1.7906, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alive = get_alive(sae_lfreq)\n",
    "cosim_matrix = get_cosims(sae, sae_lfreq, alive=alive)\n",
    "dist_matrix = torch.acos(cosim_matrix).nan_to_num(0) # distance on the unit sphere\n",
    "dist_matrix.fill_diagonal_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:\t average\n"
     ]
    }
   ],
   "source": [
    "methods = [\"average\"] #[\"ward\",\"single\",\"average\",\"complete\"]\n",
    "for method in methods:\n",
    "    print(\"Method:\\t\",method)\n",
    "    \n",
    "    res_order, res_linkage = compute_serial_matrix(dist_matrix,method)\n",
    "    \n",
    "    # plt.pcolormesh(ordered_dist_mat)\n",
    "    # # plt.xlim([0,N])\n",
    "    # # plt.ylim([0,N])\n",
    "    # plt.show()\n",
    "    \n",
    "sorted_cosim_matrix = cosim_matrix[res_order,:][:,res_order]\n",
    "sorted_jaccard = jaccard_matrix[alive,:][:,alive][res_order,:][:,res_order]\n",
    "\n",
    "torch.save(sorted_cosim_matrix, f\"/root/sparsify/{model_name}_sorted_cosim_matrix_l{p_name}.pt\")\n",
    "torch.save(sorted_jaccard, f\"/root/sparsify/{model_name}_sorted_jaccard_l{p_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SAE Features Cosine Similarity (L0.6)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating SAE: 1003520it [00:33, 85220.46it/s]                            "
     ]
    }
   ],
   "source": [
    "# cosim_matrix = get_cosims(sae,sae_lfreq)\n",
    "p_name = \"0.6\"\n",
    "# sorted_cosim_matrix = cosim_matrix.sort(descending=True, dim=-1)[0].cpu()\n",
    "plt.imshow(sorted_cosim_matrix[:100,:100], cmap=\"PiYG\", vmin=-1, vmax=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Cosine Similarity', rotation=270)\n",
    "plt.xlabel(\"SAE features\")\n",
    "plt.ylabel(\"SAE features\")\n",
    "plt.title(f\"SAE Features Cosine Similarity (L{p_name})\")\n",
    "# plt.savefig(f\"images_{cfg.seed}/ffl{p_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mncs(sae, log_freq=None, threshold=None, mode=\"mean\"):\n",
    "    # mode is either \"mean\" for mean next cosine similarity\n",
    "    # or \"max\" for max next cosine similarity\n",
    "    cosim_matrix = get_cosims(sae, log_freq, threshold)\n",
    "    for i in range(cosim_matrix.shape[0]):\n",
    "        cosim_matrix[i,i] = 0\n",
    "    if mode==\"mean\":\n",
    "        return cosim_matrix.max(dim=0)[0].mean()\n",
    "    if mode==\"max\":\n",
    "        return cosim_matrix.max(dim=0)[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mncs(sae,sae_lfreq))\n",
    "print(mncs(sae,sae_lfreq, mode=\"max\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_str = \"1w6fnqmj\"\n",
    "path = f\"/root/mats_sae_training/checkpoints/{uuid_str}/{file_strings[-1]}\"\n",
    "sae_group_l1 = torch.load(path)\n",
    "log_frequencies_l1 = torch.load(f\"/root/mats_sae_training/checkpoints/{uuid_str}/{file_strings[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0 #9\n",
    "sae_l1 = list(sae_group_l1)[id]\n",
    "sae_lfreq_l1 = log_frequencies_l1[id]\n",
    "hyp = sae_l1.cfg\n",
    "print(f\"Layer {hyp.hook_point_layer}, p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim_matrix = get_cosims(sae_l1,sae_lfreq_l1)\n",
    "dist_matrix_l1 = torch.acos(cosim_matrix).nan_to_num(0) # distance on the unit sphere\n",
    "dist_matrix_l1.fill_diagonal_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"average\"] #[\"ward\",\"single\",\"average\",\"complete\"]\n",
    "for method in methods:\n",
    "    print(\"Method:\\t\",method)\n",
    "    \n",
    "    ordered_dist_mat_l1, res_order_l1, res_linkage_l1 = compute_serial_matrix(dist_matrix_l1,method)\n",
    "    \n",
    "    # plt.pcolormesh(ordered_dist_mat)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim_matrix = get_cosims(sae_l1,sae_lfreq_l1)\n",
    "p_name = \"1\"\n",
    "sorted_cosim_matrix = torch.cos(torch.tensor(ordered_dist_mat_l1))\n",
    "plt.imshow(sorted_cosim_matrix[:100,:100], cmap=\"PiYG\", vmin=-1, vmax=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Cosine Similarity', rotation=270)\n",
    "plt.xlabel(\"SAE features\")\n",
    "plt.ylabel(\"SAE features\")\n",
    "plt.title(f\"SAE Features Cosine Similarity (L{p_name})\")\n",
    "# plt.savefig(f\"images_{cfg.seed}/ffl{p_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster by size of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim_matrix = get_cosims(sae_l1,sae_lfreq_l1)\n",
    "p_name = \"1\"\n",
    "sorted_cosim_matrix = cosim_matrix.sort(descending=True, dim=-1)[0].cpu()\n",
    "plt.imshow(sorted_cosim_matrix[:100,:100], cmap=\"PiYG\", vmin=-1, vmax=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Cosine Similarity', rotation=270)\n",
    "plt.xlabel(\"SAE features\")\n",
    "plt.ylabel(\"SAE features\")\n",
    "plt.title(f\"SAE Features Cosine Similarity (L{p_name})\")\n",
    "# plt.savefig(f\"images_{cfg.seed}/ffl{p_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mncs(sae_l1,sae_lfreq_l1))\n",
    "print(mncs(sae_l1,sae_lfreq_l1, mode=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted((sorted_cosim_matrix[:,:] > 0.98).sum(dim=-1).numpy())[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted((sorted_cosim_matrix[:,:] > 0.8).sum(dim=-1).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cosim_matrix = cosim_matrix.sort(descending=True, dim=-1)[0].cpu()\n",
    "duplicated_feature = (cosim_matrix > 0.999).sum(dim=-1).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cosim_matrix[duplicated_feature, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_picked_features = cosim_matrix[duplicated_feature].argsort(descending=True)[:30]\n",
    "cherry_picked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim_matrix = get_cosims(sae_l1,sae_lfreq_l1)\n",
    "p_name = \"1\"\n",
    "# sorted_cosim_matrix = cosim_matrix.sort(descending=True, dim=-1)[0].cpu()\n",
    "plt.imshow(cosim_matrix[cherry_picked_features][:,cherry_picked_features], cmap=\"PiYG\", vmin=-1, vmax=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Cosine Similarity', rotation=270)\n",
    "plt.xlabel(\"SAE features\")\n",
    "plt.ylabel(\"SAE features\")\n",
    "plt.title(f\"Cherrypicked SAE Features Cosine Similarity (L{p_name})\")\n",
    "# plt.savefig(f\"images_{cfg.seed}/ffl{p_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
